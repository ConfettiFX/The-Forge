/*
 * Copyright (c) 2017-2024 The Forge Interactive Inc.
 * 
 * This file is part of The-Forge
 * (see https://github.com/ConfettiFX/The-Forge).
 * 
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 * 
 *   http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
*/

// USERMACRO: SAMPLE_COUNT [1,2,4]
// Uncomment this definition to use ray differentials method for calculating
// gradients instead of screen-space projected triangles method.
//#define USE_RAY_DIFFERENTIALS

#include "shading.h.fsl"
#include "../../../../../Common_3/Renderer/VisibilityBuffer/Shaders/FSL/vb_shading_utilities.h.fsl"

// This shader loads draw / triangle Id per pixel and reconstruct interpolated vertex data.

STRUCT(VSOutput)
{
	DATA(float4, position, SV_Position);
	DATA(float2, screenPos, TEXCOORD0);
#if FT_MULTIVIEW
    DATA(FLAT(uint), ViewID, TEXCOORD3);
#endif
};

// Static descriptors
#if(SAMPLE_COUNT > 1)
	RES(Tex2DMS(float4, SAMPLE_COUNT), vbTex, UPDATE_FREQ_NONE, t0, binding = 14);
#else
#if FT_MULTIVIEW
	RES(Tex2DArray(float4), vbTex, UPDATE_FREQ_NONE, t0, binding = 14);
#else
	RES(Tex2D(float4), vbTex, UPDATE_FREQ_NONE, t0, binding = 14);
#endif/*FT_MULTIVIEW*/
#endif/*SAMPLE_COUNT > 1*/

#if SAMPLE_COUNT > 1
    RES(Tex2DMS(float, SAMPLE_COUNT), depthTex, UPDATE_FREQ_NONE, t100, binding = 15);
#else
#if FT_MULTIVIEW
	RES(Tex2DArray(float), depthTex, UPDATE_FREQ_NONE, t100, binding = 15);
#else
    RES(Tex2D(float), depthTex, UPDATE_FREQ_NONE, t100, binding = 15);
#endif/*FT_MULTIVIEW*/
#endif/*SAMPLE_COUNT > 1*/

RES(Tex2D(float), shadowMap, UPDATE_FREQ_NONE, t101, binding = 16);

#if defined(METAL) || defined(ORBIS) || defined(PROSPERO)
	RES(Tex2D(float4), diffuseMaps[MAX_TEXTURE_UNITS],  UPDATE_FREQ_NONE, t0, binding = 17);
	RES(Tex2D(float4), normalMaps[MAX_TEXTURE_UNITS],   UPDATE_FREQ_NONE, t1, binding = 17 + MAX_TEXTURE_UNITS);
	RES(Tex2D(float4), specularMaps[MAX_TEXTURE_UNITS], UPDATE_FREQ_NONE, t2, binding = 17 + MAX_TEXTURE_UNITS * 2);
#else
	RES(Tex2D(float4), diffuseMaps[MAX_TEXTURE_UNITS],  space4, t0, binding = 17);
	RES(Tex2D(float4), normalMaps[MAX_TEXTURE_UNITS],   space5, t0, binding = 17 + MAX_TEXTURE_UNITS);
	RES(Tex2D(float4), specularMaps[MAX_TEXTURE_UNITS], space6, t0, binding = 17 + MAX_TEXTURE_UNITS * 2);
#endif

RES(ByteBuffer, vertexPos,           UPDATE_FREQ_NONE, t10, binding=0);
RES(ByteBuffer, vertexTexCoord,      UPDATE_FREQ_NONE, t11, binding=1);
RES(ByteBuffer, vertexNormal,        UPDATE_FREQ_NONE, t12, binding=3);
RES(ByteBuffer, filteredIndexBuffer, UPDATE_FREQ_PER_FRAME, t14, binding=4);

RES(Buffer(uint), indirectDataBuffer,       UPDATE_FREQ_PER_FRAME, t15, binding=5);
RES(Buffer(MeshConstants), meshConstantsBuffer, UPDATE_FREQ_NONE, t16, binding=6);
RES(Buffer(LightData), lights,                  UPDATE_FREQ_NONE, t19, binding=11);

RES(ByteBuffer, lightClustersCount, UPDATE_FREQ_PER_FRAME, t20, binding=12);
RES(ByteBuffer, lightClusters,      UPDATE_FREQ_PER_FRAME, t21, binding=13);

RES(SamplerState, textureSampler, UPDATE_FREQ_NONE, s0, binding = 7);
RES(SamplerState, depthSampler, UPDATE_FREQ_NONE, s1, binding = 8);

float4 PS_MAIN( VSOutput In, SV_SampleIndex(uint) i )
{
	INIT_MAIN;
	// Load Visibility Buffer raw packed float4 data from render target
#if(SAMPLE_COUNT > 1)
	float4 visRaw = LoadTex2DMS(Get(vbTex), Get(depthSampler), uint2(In.position.xy), i);
#else
#if FT_MULTIVIEW
	float4 visRaw = LoadTex3D(Get(vbTex), Get(depthSampler), uint3(In.position.xy, In.ViewID), 0);
#else
	float4 visRaw = LoadTex2D(Get(vbTex), Get(depthSampler), uint2(In.position.xy), 0);
#endif/*FT_MULTIVIEW*/
#endif/*SAMPLE_COUNT > 1*/

	// Unpack float4 render target data into uint to extract data
	uint geomSetPrimID = packUnorm4x8(visRaw);

	// Early exit if this pixel doesn't contain triangle data
	if (geomSetPrimID == ~0u)
	{
		discard;
	}

	// Extract packed data
	uint primitiveID = (geomSetPrimID >> PRIM_ID_LOW_BIT) & PRIM_ID_MASK;
	uint geomSet = (geomSetPrimID >> GEOM_LOW_BIT) & GEOM_MASK;

	uint triIdx0 = INDEXBUFFER_OFFSET(geomSet) + (primitiveID * 3 + 0);
	uint triIdx1 = INDEXBUFFER_OFFSET(geomSet) + (primitiveID * 3 + 1);
	uint triIdx2 = INDEXBUFFER_OFFSET(geomSet) + (primitiveID * 3 + 2);

	uint index0 = LoadByte(Get(filteredIndexBuffer), triIdx0 << 2);
	uint index1 = LoadByte(Get(filteredIndexBuffer), triIdx1 << 2);
	uint index2 = LoadByte(Get(filteredIndexBuffer), triIdx2 << 2);

	// Load vertex data of the 3 vertices
	float3 v0pos = asfloat(LoadByte4(Get(vertexPos), index0 * 12)).xyz;
	float3 v1pos = asfloat(LoadByte4(Get(vertexPos), index1 * 12)).xyz;
	float3 v2pos = asfloat(LoadByte4(Get(vertexPos), index2 * 12)).xyz;

	// Transform positions to clip space
#if FT_MULTIVIEW
	float4 pos0 = mul(Get(transform)[VIEW_CAMERA].mvp.mat[In.ViewID], float4(v0pos, 1.0f));
	float4 pos1 = mul(Get(transform)[VIEW_CAMERA].mvp.mat[In.ViewID], float4(v1pos, 1.0f));
	float4 pos2 = mul(Get(transform)[VIEW_CAMERA].mvp.mat[In.ViewID], float4(v2pos, 1.0f));

	float4 wPos0 = mul(Get(transform)[VIEW_CAMERA].invVP.mat[In.ViewID],pos0);
	float4 wPos1 = mul(Get(transform)[VIEW_CAMERA].invVP.mat[In.ViewID],pos1);
	float4 wPos2 = mul(Get(transform)[VIEW_CAMERA].invVP.mat[In.ViewID],pos2);
#else
	float4 pos0 = mul(Get(transform)[VIEW_CAMERA].mvp.mat, float4(v0pos, 1.0f));
	float4 pos1 = mul(Get(transform)[VIEW_CAMERA].mvp.mat, float4(v1pos, 1.0f));
	float4 pos2 = mul(Get(transform)[VIEW_CAMERA].mvp.mat, float4(v2pos, 1.0f));

	float4 wPos0 = mul(Get(transform)[VIEW_CAMERA].invVP.mat,pos0);
	float4 wPos1 = mul(Get(transform)[VIEW_CAMERA].invVP.mat,pos1);
	float4 wPos2 = mul(Get(transform)[VIEW_CAMERA].invVP.mat,pos2);

#endif

	float2 two_over_windowsize = Get(twoOverRes);

	// Compute partial derivatives and baycentric coordinates.
	// This is necessary to interpolate triangle attributes per pixel.
	BarycentricDeriv derivativesOut = CalcFullBary(pos0,pos1,pos2,In.screenPos, two_over_windowsize);

	f3x2 texCoords = make_f3x2_cols(
			unpack2Floats(LoadByte(Get(vertexTexCoord), index0 << 2)) ,
			unpack2Floats(LoadByte(Get(vertexTexCoord), index1 << 2)) ,
			unpack2Floats(LoadByte(Get(vertexTexCoord), index2 << 2)) 
	);

	// Interpolated 1/w (one_over_w) for all three vertices of the triangle
	// using the barycentric coordinates and the delta vector
	float w = dot(float3(pos0.w, pos1.w, pos2.w),derivativesOut.m_lambda);

	// Reconstruct the Z value at this screen point performing only the necessary matrix * vector multiplication
	// operations that involve computing Z
#if FT_MULTIVIEW
	float z = w * getElem(Get(transform)[VIEW_CAMERA].projection.mat[In.ViewID], 2, 2) + getElem(Get(transform)[VIEW_CAMERA].projection.mat[In.ViewID], 3, 2);
#else
	float z = w * getElem(Get(transform)[VIEW_CAMERA].projection.mat, 2, 2) + getElem(Get(transform)[VIEW_CAMERA].projection.mat, 3, 2);
#endif

	// Calculate the world position coordinates:
	// First the projected coordinates at this point are calculated using In.screenPos and the computed Z value at this point.
	// Then, multiplying the perspective projected coordinates by the inverse view-projection matrix (invVP) produces world coordinates

#if FT_MULTIVIEW
	float3 position = mul(Get(transform)[VIEW_CAMERA].invVP.mat[In.ViewID], float4(In.screenPos * w, z, w)).xyz;
#else
	float3 position = mul(Get(transform)[VIEW_CAMERA].invVP.mat, float4(In.screenPos * w, z, w)).xyz;
#endif

#if defined(USE_RAY_DIFFERENTIALS)
#if FT_MULTIVIEW
	float3 positionDX = mul(Get(transform)[VIEW_CAMERA].invVP.mat[In.ViewID], float4((In.screenPos+two_over_windowsize.x/2) * w, z, w)).xyz;
	float3 positionDY = mul(Get(transform)[VIEW_CAMERA].invVP.mat[In.ViewID], float4((In.screenPos+two_over_windowsize.y/2) * w, z, w)).xyz;
#else
	float3 positionDX = mul(Get(transform)[VIEW_CAMERA].invVP.mat, float4((In.screenPos+two_over_windowsize.x/2) * w, z, w)).xyz;
	float3 positionDY = mul(Get(transform)[VIEW_CAMERA].invVP.mat, float4((In.screenPos+two_over_windowsize.y/2) * w, z, w)).xyz;
#endif /*FT_MULTIVIEW*/

	derivativesOut = CalcRayBary(wPos0.xyz,wPos1.xyz,wPos2.xyz,position,positionDX,positionDY,
												Get(camPos).xyz);
#endif/*USE_RAY_DIFFERENTIALS*/


	/////////////LOAD///////////////////////////////
	uint materialID = Get(indirectDataBuffer)[index0];

	// Interpolate texture coordinates and calculate the gradients for texture sampling with mipmapping support
	GradientInterpolationResults results = Interpolate2DWithDeriv(derivativesOut,texCoords);
	
	float2 texCoordDX = results.dx;
	float2 texCoordDY = results.dy;
	float2 texCoord = results.interp;

	// CALCULATE PIXEL COLOR USING INTERPOLATED ATTRIBUTES
	// Reconstruct normal map Z from X and Y
	// "NonUniformResourceIndex" is a "pseudo" function see
	// http://asawicki.info/news_1608_direct3d_12_-_watch_out_for_non-uniform_resource_index.html

	// Get textures from arrays.
	float4 normalMapRG;
	float4 diffuseColor;
	float4 specularColor;
	BeginNonUniformResourceIndex(materialID, MAX_TEXTURE_UNITS);
		normalMapRG   = SampleGradTex2D(Get(normalMaps)[materialID],   Get(textureSampler), texCoord, texCoordDX, texCoordDY);
		diffuseColor  = SampleGradTex2D(Get(diffuseMaps)[materialID],  Get(textureSampler), texCoord, texCoordDX, texCoordDY);
		specularColor = SampleGradTex2D(Get(specularMaps)[materialID], Get(textureSampler), texCoord, texCoordDX, texCoordDY);
	EndNonUniformResourceIndex();

	float3 reconstructedNormalMap;
	reconstructedNormalMap.xy = normalMapRG.ga * 2.0f - 1.0f;
	reconstructedNormalMap.z = sqrt(saturate(1.0f - dot(reconstructedNormalMap.xy, reconstructedNormalMap.xy)));

	// NORMAL INTERPOLATION
	float3x3 normals = make_f3x3_rows(
		decodeDir(unpackUnorm2x16(LoadByte(Get(vertexNormal), index0 << 2))),
		decodeDir(unpackUnorm2x16(LoadByte(Get(vertexNormal), index1 << 2))),
		decodeDir(unpackUnorm2x16(LoadByte(Get(vertexNormal), index2 << 2)))
	);
	float3 normal = normalize(InterpolateWithDeriv_float3x3(derivativesOut, normals));
	
	//Calculate pixel normal and tangent vectors
	f3x3 wPositions = make_f3x3_cols(
			wPos0.xyz,
			wPos1.xyz,
			wPos2.xyz
	);

	DerivativesOutput wPosDer = Cal3DDeriv(derivativesOut, wPositions);
	DerivativesOutput uvDer = { float3(results.dx, 0.0),  float3(results.dy, 0.0) };
	normal = perturb_normal(reconstructedNormalMap, normal, wPosDer, uvDer);

	// Sample Diffuse color
#if FT_MULTIVIEW
	float4 posLS = mul(Get(transform)[VIEW_SHADOW].vp.mat[In.ViewID], float4(position, 1.0f));
#else
	float4 posLS = mul(Get(transform)[VIEW_SHADOW].vp.mat, float4(position, 1.0f));
#endif

	float Roughness = clamp(specularColor.a, 0.05f, 0.99f);
	float Metallic = specularColor.b;

	float ao = calculateAoContrib(
		Get(depthTexSize),
		Get(aoIntensity),
		Get(aoQuality),
		Get(CameraPlane).y,
		Get(CameraPlane).x,
		Get(frustumPlaneSizeNormalized),
		In.position.xy,
		Get(depthTex),
		Get(depthSampler));

	bool isTwoSided = (geomSet == GEOMSET_ALPHA_CUTOUT) && bool(Get(meshConstantsBuffer)[materialID].twoSided);
	bool isBackFace = false;

	float3 ViewVec = normalize(Get(camPos).xyz - position.xyz);
	
	//if it is backface
	//this should be < 0 but our mesh's edge normals are smoothed, badly
	if (isTwoSided && dot(normal, ViewVec) < 0.0f)
	{
		//flip normal
		normal = -normal;
		isBackFace = true;
	}

	float3 HalfVec = normalize(ViewVec - Get(lightDir).xyz);
	float3 ReflectVec = reflect(-ViewVec, normal);
	float NoV = saturate(dot(normal, ViewVec));

	float NoL = dot(normal, -Get(lightDir).xyz);	

	// Deal with two faced materials
	NoL = (isTwoSided ? abs(NoL) : saturate(NoL));

	float3 shadedColor = f3(0.0f);

	// calculate color contribution from specular lighting
	float3 F0 = f3(0.08); // 0.08 is the index of refraction
	float3 SpecularColor = lerp(F0, diffuseColor.rgb, Metallic);
	float3 DiffuseColor = lerp(diffuseColor.rgb, f3(0.0), Metallic);

	float shadowFactor = 1.0f;
	float fLightingMode = saturate(float(Get(lightingMode)));

	shadedColor = calculateIllumination(
		    normal,
		    ViewVec,
			HalfVec,
			ReflectVec,
			NoL,
			NoV,
			Get(camPos).xyz,
			Get(esmControl),
			Get(lightDir).xyz,
			posLS,
			position,
			Get(shadowMap),
			DiffuseColor,
			SpecularColor,
			Roughness,
			Metallic,
			Get(depthSampler),
			isBackFace,
			fLightingMode,
			shadowFactor);
	
	shadedColor = shadedColor * Get(lightColor).rgb * Get(lightColor).a * NoL;
	if (Get(visualizeAo) > 0)
		shadedColor = f3(ao);
	
	// point lights
	// Find the light cluster for the current pixel
	uint2 clusterCoords = uint2(floor((In.screenPos * 0.5f + 0.5f) * float2(LIGHT_CLUSTER_WIDTH, LIGHT_CLUSTER_HEIGHT)));

	uint numLightsInCluster = LoadByte(Get(lightClustersCount), LIGHT_CLUSTER_COUNT_POS(clusterCoords.x, clusterCoords.y) << 2);

	// Accumulate light contributions
	for (uint j = 0; j < numLightsInCluster; ++j)
	{
		uint lightId = LoadByte(Get(lightClusters), LIGHT_CLUSTER_DATA_POS(j, clusterCoords.x, clusterCoords.y) << 2);

		shadedColor += pointLightShade(
		normal,
		ViewVec,
		HalfVec,
		ReflectVec,
		NoL,
		NoV,
		Get(lights)[lightId].position.xyz,
		Get(lights)[lightId].color.xyz,
		Get(camPos).xyz,
		Get(lightDir).xyz,
		posLS,
		position,
		DiffuseColor,
		SpecularColor,
		Roughness,
		Metallic,		
		isBackFace,
		fLightingMode);
	}

	float ambientIntencity = 0.05f * ao;
	float3 ambient = diffuseColor.rgb * ambientIntencity;

	float3 FinalColor = shadedColor + ambient;

	RETURN(float4(FinalColor, 1.0));
}
